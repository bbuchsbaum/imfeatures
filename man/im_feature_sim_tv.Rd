% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/im_features_tv.R
\name{im_feature_sim_tv}
\alias{im_feature_sim_tv}
\title{Compute Similarity Matrix using thingsvision Features}
\usage{
im_feature_sim_tv(
  impaths,
  model_name,
  source,
  module_names,
  metric = "cosine",
  flatten_acts = TRUE,
  device = "cuda",
  pretrained = TRUE,
  model_parameters = NULL,
  batch_size = 32,
  temp_out_dir = tempdir()
)
}
\arguments{
\item{impaths}{Character vector. A vector of full file paths to the images.
The order determines the rows/columns of the output similarity matrices.
Assumes images share a common parent directory (see `im_features_tv` details).}

\item{model_name}{Character string. The name of the `thingsvision` model architecture
(e.g., `"resnet50"`, `"clip"`). Must be a non-empty string.}

\item{source}{Character string. The source library of the model
(e.g., `"torchvision"`, `"custom"`). Must be a non-empty string.}

\item{module_names}{Character vector. The specific layer/module names within the
model from which to extract features for similarity calculation. Must contain at
least one non-empty string. Use
`tv_show_model(tv_get_extractor(model_name, source))` to find valid names.}

\item{metric}{Character string. The similarity metric to use. Defaults to "cosine".
Common options include "cosine", "correlation". See `proxy::pr_simil_funs`
for available metrics supported by the `proxy` package.}

\item{flatten_acts}{Logical. Should activations from the specified `module_names`
be flattened into vectors before calculating similarity? This is almost
always required for standard similarity metrics like cosine or correlation.
Defaults to TRUE. Setting to FALSE will likely cause errors unless the
metric can handle multi-dimensional arrays and the chosen layer output
is suitable.}

\item{device}{Character string. The compute device ("cpu", "cuda", "cuda:0").
Defaults to "cuda".}

\item{pretrained}{Logical. Use pretrained model weights? Defaults to TRUE.}

\item{model_parameters}{Named list (optional). Additional parameters for specific
models (e.g., `list(variant = "ViT-B/32")` for CLIP). Defaults to NULL.}

\item{batch_size}{Integer. Batch size for feature extraction. Defaults to 32.}

\item{temp_out_dir}{Character string. Temporary directory for internal file list
used during feature extraction. Defaults to `tempdir()`.}
}
\value{
A named list where each element corresponds to a `module_name` provided
        in the input. Each element contains a square similarity matrix
        (n_images x n_images).
}
\description{
Calculates the pairwise similarity between a set of images based on features
extracted from specified model layers using the `thingsvision` backend.
}
\details{
This function streamlines the process of calculating representational similarity
matrices (RSMs) using features from the `thingsvision` ecosystem.

\strong{Workflow:}
\enumerate{
 \item It iterates through each `module_name` provided.
 \item For each module, it calls \code{\link{im_features_tv}} to extract features
       for all images specified in `impaths`. The `flatten_acts` parameter is
       crucial here to ensure features are in a suitable format (usually 2D matrix)
       for standard similarity calculation.
 \item It then calculates the full pairwise similarity matrix for the extracted
       features using the specified `metric` via the `proxy` package (or `coop`
       for optimized cosine).
 \item Rownames and colnames of the similarity matrices are set based on the
       image basenames.
}

\strong{Memory Considerations:}
This function extracts features for *all* images for a given module *before*
calculating the similarity matrix for that module. This is generally efficient
if the features for all images fit into memory. It does *not* currently implement
the pair-by-pair extraction (`lowmem=TRUE`) strategy found in the original
`im_feature_sim` function, as the primary bottleneck is often feature extraction
itself when using large models. If memory issues arise during the similarity
calculation step (after feature extraction), consider using metrics optimized
for memory or processing subsets of images. The `output_dir` option in
`im_features_tv` can handle cases where the features *themselves* don't fit
in memory during extraction.

\strong{Prerequisites:}
Requires a correctly configured Python environment with `thingsvision` installed.
Use \code{\link{install_thingsvision}} and configure `reticulate` before use.
}
\examples{
\dontrun{
# --- Prerequisites ---
# install_thingsvision()
library(imfeatures)
library(reticulate)
tryCatch({
  use_condaenv("r-thingsvision", required = TRUE)
  tv <- import("thingsvision")
}, error = function(e) message("Python env 'r-thingsvision' not found."))

# --- Example Usage ---
# Create dummy image files
image_dir <- file.path(tempdir(), "sim_test_images")
dir.create(image_dir, showWarnings = FALSE)
png(file.path(image_dir, "cat.png")); plot(1:5); dev.off()
png(file.path(image_dir, "dog.png")); plot(rnorm(50)); dev.off()
png(file.path(image_dir, "car.png")); plot(1:20); dev.off()
image_paths <- list.files(image_dir, full.names = TRUE, pattern = "\\\\.png$")

# Calculate similarity based on ResNet-18 avgpool and layer4 features
sim_results <- im_feature_sim_tv(
  impaths = image_paths,
  model_name = "resnet18",
  source = "torchvision",
  module_names = c("avgpool", "layer4"), # Request features from two layers
  metric = "cosine",
  flatten_acts = TRUE, # Flatten layer4 activations
  device = "cpu"
)

# Explore results
print(names(sim_results))
print(dim(sim_results$avgpool))
print(sim_results$avgpool)

# Example showing argument validation (will error)
im_feature_sim_tv(
  impaths = image_paths,
  model_name = "",
  source = "torchvision",
  module_names = "avgpool"
)
#> Error: 'model_name' must be a non-empty character string.

# Clean up
unlink(image_dir, recursive = TRUE)
}
}
\seealso{
\code{\link{im_features_tv}}, \code{\link{install_thingsvision}}, \code{\link{tv_get_extractor}}
}
